{"cells":[{"cell_type":"markdown","source":["# Checkpointing\n","\n","Your task is to implement checkpointing for a MLP using NumPy.\n","\n","You are free to use the implementation of a MLP and the backpropagation algorithm that you have developed during lab sessions.\n","\n","The key takeaway from this task is that with checkpointing we can trade off the computational resources needed to compute the forward pass of the network for the memory requirement needed to perform a backward pass in the network, which is often a major bottleneck when training large networks. In plain english, we can slightly increase the time required for training our network to save some of our GPU's precious memory.\n","\n","## What is checkpointing?\n","\n","The aim of checkpointing is to save every $n$-th layer's (e.g. every 2-nd layer's) forward result (instead of saving every layer's forward result as in plain backpropagation) and use these checkpoints for recomputing the forward pass of the network upon doing a backward pass. Checkpoint layers are kept in memory after the forward pass, while the remaining activations are recomputed at most once. After being recomputed, the non-checkpoint layers are kept in memory until they are no longer required."],"metadata":{"collapsed":false,"id":"AFmT255Zqkz3"}},{"cell_type":"markdown","source":["# What should be done\n","\n","1. Take the implementation a MLP trained with backpropagation. Analyze the algorithm with respect to the memory that is used by the algorithm with respect to the number of hidden layers.\n","\n","2. Implement a class NetworkWithCheckpointing that inherits from the Network class defined during lab sessions by:\n","    a) implementing a method `forward_between_checkpoints` that will recompute the forward pass of the network using one of the checkpointed layers\n","    b) override the method `backprop` to use only checkpointed layers and otherwise compute the activations using `forward_between_checkpoints` method and keep it in memory until no longer needed.\n","\n","3. Train your network with checkpoinintg on MNIST. Compare running times and memory usage with respect to the network without checkpointing.\n"],"metadata":{"collapsed":false,"id":"ZL1L43hjqkz6"}},{"cell_type":"markdown","source":["# Implement Checkpointing for a MLP"],"metadata":{"collapsed":false,"id":"nSw_2ZDIqkz6"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import random\n","import numpy as np\n","from torchvision import datasets, transforms"],"metadata":{"id":"JiuOpBFRqkz7"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-03 08:30:09--  https://s3.amazonaws.com/img-datasets/mnist.npz\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.76.230\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.76.230|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11490434 (11M) [application/octet-stream]\n","Saving to: ‘mnist.npz’\n","\n","mnist.npz           100%[===================>]  10.96M  52.6MB/s    in 0.2s    \n","\n","2022-11-03 08:30:09 (52.6 MB/s) - ‘mnist.npz’ saved [11490434/11490434]\n","\n"]}],"source":["!wget -O mnist.npz https://s3.amazonaws.com/img-datasets/mnist.npz"],"metadata":{"id":"fP3Dne96qkz8","outputId":"3bde8486-51a3-45ed-9e45-c3e7a6a75917","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667464210629,"user_tz":-60,"elapsed":11,"user":{"displayName":"Michał Janik","userId":"10483929333441523386"}}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["# Let's read the mnist dataset\n","\n","def load_mnist(path='mnist.npz'):\n","    with np.load(path) as f:\n","        x_train, _y_train = f['x_train'], f['y_train']\n","        x_test, _y_test = f['x_test'], f['y_test']\n","\n","    x_train = x_train.reshape(-1, 28 * 28) / 255.\n","    x_test = x_test.reshape(-1, 28 * 28) / 255.\n","\n","    y_train = np.zeros((_y_train.shape[0], 10))\n","    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n","\n","    y_test = np.zeros((_y_test.shape[0], 10))\n","    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n","\n","    return (x_train, y_train), (x_test, y_test)\n","\n","(x_train, y_train), (x_test, y_test) = load_mnist()"],"metadata":{"id":"YE8ZObAnqkz9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from scipy.special import softmax\n","from timeit import default_timer as timer\n","\n","def sigmoid(z):\n","    return 1.0/(1.0+np.exp(-z))\n","\n","def relu(z):\n","  return np.maximum(0, z)\n","\n","class Network(object):\n","    def __init__(self, sizes, momentum=0.9, l2=0.01, drop_rate_input=0.9, drop_rate_hidden=0.5):\n","        self.num_layers = len(sizes)\n","        self.sizes = sizes\n","        self.momentum = momentum\n","        self.l2=l2\n","\n","        assert 0 <= drop_rate_input <= 1\n","        assert 0 <= drop_rate_hidden <= 1\n","\n","        self.drop_rate_input = drop_rate_input\n","        self.drop_rate_hidden = drop_rate_hidden\n","\n","        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n","        self.weights = [np.random.randn(y, x) \n","                        for x, y in zip(sizes[:-1], sizes[1:])]\n","        \n","        # momentum\n","        self.weights_momentum = [np.zeros_like(w) for w in self.weights]\n","        self.biases_momentum = [np.zeros_like(b) for b in self.biases]\n","\n","    def feedforward(self, a):\n","        a = a.T\n","        for layer_index, (b, w) in enumerate(zip(self.biases, self.weights)):\n","            a = np.matmul(w, a)+b\n","            if layer_index < self.num_layers-2:\n","              a = sigmoid(a)\n","            else:\n","              a = softmax(a, axis=0)\n","        return a\n","    \n","    def update_mini_batch(self, mini_batch, eta):\n","        nabla_b, nabla_w, time_used, mem_used, max_mem_objects = self.backprop(mini_batch[0].T,mini_batch[1].T)\n","        nabla_b = [b / len(mini_batch[0]) for b in nabla_b]\n","        nabla_w = [w / len(mini_batch[0]) for w in nabla_w]\n","\n","        # l2 regularization\n","        self.weights = [w*(1-self.l2*eta) for w in self.weights]\n","\n","        self.biases_momentum = [self.momentum*b + (1 - self.momentum)*np.multiply(eta, nb) for b, nb in zip(self.biases_momentum, nabla_b)]\n","        self.weights_momentum = [self.momentum*w + (1 - self.momentum)*np.multiply(eta, nw) for w, nw in zip(self.weights_momentum, nabla_w)]\n","            \n","        self.weights = [w-nw \n","                        for w, nw in zip(self.weights, self.weights_momentum)]\n","        self.biases = [b-nb \n","                       for b, nb in zip(self.biases, self.biases_momentum)]\n","\n","        self.time_used.append(time_used)\n","        self.mem_used.append(mem_used)\n","        self.max_mem_objects.append(max_mem_objects)\n","\n","        \n","    def backprop(self, x, y):\n","        start_time = timer()\n","\n","        g = x\n","        \n","        # dropout input\n","        mask = (np.random.rand(*g.shape) < self.drop_rate_input).astype(np.float32)\n","        g = mask * g / self.drop_rate_input\n","\n","\n","        gs = [g] # list to store all the gs, layer by layer\n","\n","\n","        for layer_index, (b, w) in enumerate(zip(self.biases, self.weights)):\n","            f = np.dot(w, g)+b\n","            if layer_index < self.num_layers-2:\n","              # dropout hidden layers\n","              mask = (np.random.rand(*g.shape) < self.drop_rate_hidden).astype(np.float32)\n","              g = mask * g / self.drop_rate_hidden\n","              \n","              g = sigmoid(f)\n","            else:\n","              g = softmax(f, axis=0)\n","\n","            gs.append(g)\n","\n","        dLdg = self.cost_derivative(gs[-1], y)\n","        dLdfs = []\n","        for layer_index, (w,g) in reversed(list(enumerate(zip(self.weights,gs[1:])))):\n","            if layer_index < self.num_layers-2:\n","              dLdf = np.multiply(dLdg,np.multiply(g,1-g))\n","            else:\n","              dLdf = dLdg\n","            dLdfs.append(dLdf)\n","            dLdg = np.matmul(w.T, dLdf)\n","        \n","        dLdWs = [np.matmul(dLdf,g.T) for dLdf,g in zip(reversed(dLdfs),gs[:-1])] \n","        dLdBs = [np.sum(dLdf,axis=1).reshape(dLdf.shape[0],1) for dLdf in reversed(dLdfs)] \n","\n","        mem_used =  sum([x.nbytes if x is not None else 0 for x in gs[1:]])\n","        max_mem_objects = len([x for x in gs[1:] if x is not None])\n","        end_time = timer()\n","        \n","        return dLdBs, dLdWs, end_time-start_time, mem_used, max_mem_objects\n","\n","    def evaluate(self, test_data):\n","        pred = np.argmax(self.feedforward(test_data[0]),axis=0)\n","        corr = np.argmax(test_data[1],axis=1).T\n","        return np.mean(pred==corr)\n","    \n","    def cost_derivative(self, output_activations, y):\n","        return (output_activations-y) \n","    \n","    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n","        self.time_used = []\n","        self.mem_used = []\n","        self.max_mem_objects = []\n","\n","        best_acc = -1\n","        x_train, y_train = training_data\n","        if test_data:\n","            x_test, y_test = test_data\n","        for j in range(epochs):\n","            for i in range(x_train.shape[0] // mini_batch_size):\n","                x_mini_batch = x_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n","                y_mini_batch = y_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n","                self.update_mini_batch((x_mini_batch, y_mini_batch), eta)\n","            if test_data:\n","                accuracy = self.evaluate((x_test, y_test))\n","                best_acc = max(best_acc, accuracy)\n","                print(\"Epoch: {0}, Accuracy: {1}\".format(j, accuracy))\n","            else:\n","                print(\"Epoch: {0}\".format(j))\n","        print(f\"\\nBest accuracy: {best_acc}\")\n","        avg_time = sum(self.time_used)/epochs\n","        avg_mem = sum(self.mem_used)/(len(self.mem_used) * 1024 * 1024)\n","        max_mem_objects = max(self.max_mem_objects)\n","\n","        print(f\"Mean time / epoch  : {avg_time:.3f}s\")\n","        print(f\"Mean memory / batch: {avg_mem:.2f}Mb\")\n","        print(f\"Max no. of objects in memory: {max_mem_objects}\")\n","\n","\n"],"metadata":{"id":"sacpzeqXqkz9"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["class NetworkWithCheckpointing(Network):\n","\n","    def __init__(self, sizes, checkpoint_every_nth_layer: int = 0, *args, **kwargs):\n","        super().__init__(sizes, *args, **kwargs)\n","        self.checkpoint_every_nth_layer = max(checkpoint_every_nth_layer, 1)\n","\n","    def forward_between_checkpoints(self, a, checkpoint_idx_start, layer_idx_end):\n","        gs = []\n","        g = a\n","        for layer_index in range(checkpoint_idx_start, layer_idx_end):\n","            w = self.weights[layer_index]\n","            b = self.biases[layer_index]\n","\n","            f = np.dot(w, g)+b\n","\n","            # dropout hidden layers\n","            mask = (np.random.rand(*g.shape) < self.drop_rate_hidden).astype(np.float32)\n","            g = mask * g / self.drop_rate_hidden\n","          \n","            g = sigmoid(f)\n","            gs.append(g)\n","\n","        return gs\n","\n","    def backprop(self, x, y):\n","        start_time = timer()\n","\n","        g = x\n","        \n","        # dropout input\n","        mask = (np.random.rand(*g.shape) < self.drop_rate_input).astype(np.float32)\n","        g = mask * g / self.drop_rate_input\n","\n","\n","        gs = [None] * (len(self.weights) + 1) # list to store every nth gs\n","        gs[0] = g\n","\n","        for layer_index, (b, w) in enumerate(zip(self.biases, self.weights)):\n","            f = np.dot(w, g)+b\n","            if layer_index < self.num_layers-2:\n","              # dropout hidden layers\n","              mask = (np.random.rand(*g.shape) < self.drop_rate_hidden).astype(np.float32)\n","              g = mask * g / self.drop_rate_hidden\n","      \n","              g = sigmoid(f)\n","            else:\n","              g = softmax(f, axis=0)\n","\n","            if layer_index % self.checkpoint_every_nth_layer == 0:\n","              gs[layer_index+1] = g\n","\n","        # backward pass\n","        dLdg = self.cost_derivative(g, y)\n","        dLdf = dLdg\n","\n","        dLdWs, dLdBs = [], []\n","        last_checkpoint_index = len(self.weights) - ((len(self.weights) - 1) % self.checkpoint_every_nth_layer)\n","        was_checkpoint_propagated = False\n","\n","        max_mem = -1\n","        max_mem_objects = -1\n","        for layer_index, w in reversed(list(enumerate(self.weights))):\n","            if layer_index < last_checkpoint_index:\n","              # clear unnecessary memory\n","              for gs_index in range(last_checkpoint_index, min(len(gs)-1, last_checkpoint_index+self.checkpoint_every_nth_layer)+1):\n","                gs[gs_index] = None\n","\n","              # update checkpoint\n","              last_checkpoint_index = max(0, last_checkpoint_index - self.checkpoint_every_nth_layer)\n","              was_checkpoint_propagated = False\n","\n","\n","            if not was_checkpoint_propagated:\n","              checkpoint_out = gs[last_checkpoint_index]\n","\n","              gs_between_checkpoints = self.forward_between_checkpoints(checkpoint_out, last_checkpoint_index, layer_index)\n","              for index, g in enumerate(gs_between_checkpoints):\n","                gs_index = last_checkpoint_index + 1 + index\n","                gs[gs_index] = g\n","                \n","              was_checkpoint_propagated = True\n","            \n","            g = gs[layer_index]\n","\n","            dLdWs.append(np.matmul(dLdf,g.T))\n","            dLdBs.append(np.sum(dLdf,axis=1).reshape(dLdf.shape[0],1))\n","\n","            dLdg = np.matmul(w.T, dLdf)\n","            dLdf = np.multiply(dLdg,np.multiply(g,1-g))\n","\n","            current_mem = sum([x.nbytes if x is not None else 0 for x in gs[1:]])\n","            max_mem = max(current_mem, max_mem)\n","\n","            mem_objects = len([x for x in gs[1:] if x is not None])\n","            if mem_objects > max_mem_objects:\n","              # print(['X' if x is not None else 'O' for x in gs[1:]])\n","              max_mem_objects = mem_objects\n","\n","        end_time = timer()\n","        \n","        return reversed(dLdBs), reversed(dLdWs), end_time-start_time, max_mem, max_mem_objects\n"],"metadata":{"id":"Mn1HDKCsqkz9"}},{"cell_type":"code","source":["layers = [784, 100, 200, 200, 200, 200, 200, 200, 200, 200, 200, 10]\n","epochs = 1\n","\n","network = Network(layers, momentum=0.9, l2=1e-3, drop_rate_input=0.9, drop_rate_hidden=0.5)\n","network.SGD((x_train, y_train), epochs=epochs, mini_batch_size=1000, eta=0.5, test_data=(x_test, y_test))"],"metadata":{"id":"HS1uveX9Kd0M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667470229950,"user_tz":-60,"elapsed":20556,"user":{"displayName":"Michał Janik","userId":"10483929333441523386"}},"outputId":"cfa5f950-010e-48cd-c74d-c6342ba70859"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.1605\n","\n","Best accuracy: 0.1605\n","Mean time / epoch  : 18.519s\n","Mean memory / batch: 14.57Mb\n","Max no. of objects in memory: 11\n"]}]},{"cell_type":"code","source":["network = NetworkWithCheckpointing(layers, momentum=0.9, l2=1e-3, drop_rate_input=0.9, drop_rate_hidden=0.5, checkpoint_every_nth_layer=2)\n","network.SGD((x_train, y_train), epochs=epochs, mini_batch_size=1000, eta=0.5, test_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0Q--UxaZSby","executionInfo":{"status":"ok","timestamp":1667470258341,"user_tz":-60,"elapsed":28394,"user":{"displayName":"Michał Janik","userId":"10483929333441523386"}},"outputId":"51b8de5d-f9c7-4a49-c226-d473b3a5dded"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.2721\n","\n","Best accuracy: 0.2721\n","Mean time / epoch  : 23.933s\n","Mean memory / batch: 8.39Mb\n","Max no. of objects in memory: 6\n"]}]},{"cell_type":"code","source":["network = NetworkWithCheckpointing(layers, momentum=0.9, l2=1e-3, drop_rate_input=0.9, drop_rate_hidden=0.5, checkpoint_every_nth_layer=3)\n","network.SGD((x_train, y_train), epochs=epochs, mini_batch_size=1000, eta=0.5, test_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mt9avsSaaOfj","executionInfo":{"status":"ok","timestamp":1667470358564,"user_tz":-60,"elapsed":26310,"user":{"displayName":"Michał Janik","userId":"10483929333441523386"}},"outputId":"0bbda767-ad2d-4e33-db25-64b26bd988e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.2116\n","\n","Best accuracy: 0.2116\n","Mean time / epoch  : 24.390s\n","Mean memory / batch: 6.87Mb\n","Max no. of objects in memory: 5\n"]}]},{"cell_type":"markdown","source":["Backprop with checkpointing with $ n $ hidden layers and $\\text{checkpoint_every_nth_layer}=k$ in the worst case needs approximately $ \\lfloor \\frac{n}{k} \\rfloor + k $ objects stored in memory in peak: $ \\lfloor \\frac{n}{k} \\rfloor $ for storing the checkpoints and $k$ for storing the outputs between checkpoints, while the default solution requires storing $n$ layers. Therefore, increasing k decreases memory consuption (to a certain moment).\n","\n","However, backprop with checkpointing needs to to forward steps $2n-n/k$ times instead of $n$ times, which means that increasing $k$ results in increasing time taken."],"metadata":{"id":"5LwJ3s4_8W9a"}},{"cell_type":"code","source":[],"metadata":{"id":"kE13vVvv_WFN","executionInfo":{"status":"ok","timestamp":1668595553129,"user_tz":-60,"elapsed":3,"user":{"displayName":"Michał Janik","userId":"10483929333441523386"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[{"file_id":"https://github.com/mim-uw/dnn-2022-23/blob/master/hw1-checkpoints-student.ipynb","timestamp":1667213453278}]}},"nbformat":4,"nbformat_minor":0}